---
title: "HLM_TST"
author: "Clara Belitz"
date: "10/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lme4)      # for fitting model
library(lmerTest)  # for getting df, t and p for fixed effects
library(texreg)    # nice formated output (laTex included)
library(optimx)    # needed for changing algorithm
```

## Data Setup

We need to load the general training data, make student ID and gender factor variables (with "none" as the default level for gender), and then make a training dataframe for each machine learning model of interest, including creating a new variable called "Correct" that notes whether the model was correct for a given prediction. These are random forest, decision tree, neural net, XGBoost, and a dummy model, as defined in the previous detector rot paper.

```{r data-setup, echo=FALSE}
# load training data
detector_rot_data <- read.csv("data/training_with_gender.csv", header=TRUE)

#make student id and gender factor variables
detector_rot_data$StudentID<-as.factor(detector_rot_data$StudentID)
detector_rot_data$gender = factor(detector_rot_data$gender, levels=c("none", "male", "female")) # none is baseline level

# load data for each model
random_forest_data <- read.csv("data/Random Forest_finalPredictions_with_proba.csv", header=TRUE)
decision_tree_data <- read.csv("data/Decision Tree_finalPredictions_with_proba.csv", header=TRUE)
neural_net_data <- read.csv("data/Neural Net_finalPredictions_with_proba.csv", header=TRUE)
xg_boost_data <-  read.csv("data/XGBoost_finalPredictions_with_proba.csv", header=TRUE)
dummy_data <-  read.csv("data/Dummy_finalPredictions_with_proba.csv", header=TRUE)


# create training data for each model (unique dataframe for each)
rf_prediction_df = data.frame(detector_rot_data)
rf_prediction_df$prediction <- random_forest_data$label_predict

dt_prediction_df = data.frame(detector_rot_data)
dt_prediction_df$prediction <- decision_tree_data$label_predict

nn_prediction_df = data.frame(detector_rot_data)
nn_prediction_df$prediction <- neural_net_data$label_predict

xgb_prediction_df = data.frame(detector_rot_data)
xgb_prediction_df$prediction <- xg_boost_data$label_predict

dummy_prediction_df = data.frame(detector_rot_data)
dummy_prediction_df$prediction <- dummy_data$label_predict

# create column to note whether a given observation was predicted correctly or not, for each model
rf_prediction_df$correct<- with(rf_prediction_df, ifelse(rf_prediction_df$prediction == rf_prediction_df$Target, 1, 0))
dt_prediction_df$correct <- with(dt_prediction_df, ifelse(dt_prediction_df$prediction == dt_prediction_df$Target, 1, 0))
nn_prediction_df$correct <- with(nn_prediction_df, ifelse(nn_prediction_df$prediction == nn_prediction_df$Target, 1, 0))
xgb_prediction_df$correct <- with(xgb_prediction_df, ifelse(xgb_prediction_df$prediction == xgb_prediction_df$Target, 1, 0))
dummy_prediction_df$correct <- with(dummy_prediction_df, ifelse(dummy_prediction_df$prediction == dummy_prediction_df$Target, 1, 0))

```

## Basic HLM explaining whether the model was correct for each model
###Analogous to Overall Accuracy Equality.

```{r correct, echo=FALSE}
rf_modela <- glmer(correct ~ gender + (1 | StudentID), data=rf_prediction_df,
                   family=binomial)
summary(rf_modela)


dt_modela <- glmer(correct ~ gender + (1 | StudentID), data=dt_prediction_df,
                   family=binomial)
summary(dt_modela)

nn_modela <- glmer(correct ~ gender + (1 | StudentID), data=nn_prediction_df,
                   family=binomial)
summary(nn_modela)

xgb_modela <- glmer(correct ~ gender + (1 | StudentID), data=xgb_prediction_df,
                    family=binomial)
summary(xgb_modela)

dummy_modela <- glmer(correct ~ gender + (1 | StudentID), data=dummy_prediction_df,
                      family=binomial)
summary(dummy_modela)
```

### Analogous to Statistical Parity
We can see in the basic model that there are no strong effects of gender on the prediction accuracy. Only 1 in 5 models has a significant value, which can possibly be explained by chance. We can try the models again looking at the prediction of positives only and negatives only, rather than whether the model was correct in general. This is analogous to statistical parity. Because the positive and negative models would be equivalent but reversedm we can run the model just once.

```{r prediction, echo=FALSE}
rf_prediction_a <- glmer(prediction ~ gender + (1 | StudentID), data=rf_prediction_df,
                         family=binomial)
summary(rf_prediction_a)

dt_prediction_a <- glmer(prediction ~ gender + (1 | StudentID), data=dt_prediction_df,
                         family=binomial)
summary(dt_prediction_a)

nn_prediction_a<- glmer(prediction ~ gender + (1 | StudentID), data=nn_prediction_df,
                        family=binomial)
summary(nn_prediction_a)

xgb_prediction_a <- glmer(prediction ~ gender + (1 | StudentID), data=xgb_prediction_df,
                          family=binomial)
summary(xgb_prediction_a)

dummy_prediction_a <- glmer(prediction ~ gender + (1 | StudentID), data=dummy_prediction_df,
                            family=binomial)
summary(dummy_prediction_a)

```
This also shows no significant effect. So gender is unlikely to affect the prediction with our current data, and statistical parity is met. There is, however, a general pattern emerging where female students are more likely to have incorrect predictions.

### Analogous to conditional procedure accuracy (break groups into pos and neg labels)
We can look at conditional procedure accuracy with two HLMs per machine learning model. We first break the datasets into two groups based on the ground truth labels: observations where gaming was occuring and observations were gaming was not occuring.

We then look at likelihood of correct predictions for each gender group within the subset.
```{r dataprep_cpa, echo=FALSE}
rf_gaming_true_labels = rf_prediction_df[rf_prediction_df$Target == 1, ]
dt_gaming_true_labels = dt_prediction_df[dt_prediction_df$Target == 1, ]
nn_gaming_true_labels = nn_prediction_df[nn_prediction_df$Target == 1, ]
xgb_gaming_true_labels = xgb_prediction_df[xgb_prediction_df$Target == 1, ]
dummy_gaming_true_labels = dummy_prediction_df[dummy_prediction_df$Target == 1, ]

rf_gaming_false_labels = rf_prediction_df[rf_prediction_df$Target == 0, ]
dt_gaming_false_labels = dt_prediction_df[dt_prediction_df$Target == 0, ]
nn_gaming_false_labels = nn_prediction_df[nn_prediction_df$Target == 0, ]
xgb_gaming_false_labels = xgb_prediction_df[xgb_prediction_df$Target == 0, ]
dummy_gaming_false_labels = dummy_prediction_df[dummy_prediction_df$Target == 0, ]

rf_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=rf_gaming_true_labels,
                            family=binomial)
summary(rf_prediction_true)

rf_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=rf_gaming_false_labels,
                            family=binomial)
summary(rf_prediction_false)
# -------------------------------

# dt_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=dt_gaming_true_labels,
#                             family=binomial)
# summary(dt_prediction_true)

dt_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=dt_gaming_false_labels,
                             family=binomial)
summary(dt_prediction_false)

# -------------------------------

nn_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=nn_gaming_true_labels,
                            family=binomial)
summary(nn_prediction_true)

nn_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=nn_gaming_false_labels,
                             family=binomial)
summary(nn_prediction_false)

# -------------------------------

xgb_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=xgb_gaming_true_labels,
                            family=binomial)
summary(xgb_prediction_true)

xgb_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=xgb_gaming_false_labels,
                             family=binomial)
summary(xgb_prediction_false)
# -------------------------------

dummy_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=dummy_gaming_true_labels,
                            family=binomial)
summary(dummy_prediction_true)

dummy_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=dummy_gaming_false_labels,
                             family=binomial)
summary(dummy_prediction_false)
```
The true gaming labels group is quite small, 25 observations over 13 students, so it is hard to draw conclusions. But, for the non-gaming labels, we again see the pattern of non-significance but generally worse results for genderfemale.

We can also notice that some of the true models fail to converge or are even non-invertable, which I will be looking into further.

### Analogous to conditional use accuracy (break groups into pos and neg predictions)
We can also look at conditional use accuracy with two HLMs per machine learning model. We first break the datasets into two groups based on the predicted labels: observations where gaming was predicted as occurring and observations were gaming was not predicted.

We then look at likelihood of correct predictions for each gender group within the subset.
```{r models_cua, echo=FALSE}
rf_predicted_gaming = rf_prediction_df[rf_prediction_df$prediction == 1, ]
dt_predicted_gaming = dt_prediction_df[dt_prediction_df$prediction == 1, ]
nn_predicted_gaming = nn_prediction_df[nn_prediction_df$prediction == 1, ]
xgb_predicted_gaming = xgb_prediction_df[xgb_prediction_df$prediction == 1, ]
dummy_predicted_gaming = dummy_prediction_df[dummy_prediction_df$prediction == 1, ]

rf_predicted_not_gaming = rf_prediction_df[rf_prediction_df$prediction == 0, ]
dt_predicted_not_gaming = dt_prediction_df[dt_prediction_df$prediction == 0, ]
nn_predicted_not_gaming = nn_prediction_df[nn_prediction_df$prediction == 0, ]
xgb_predicted_not_gaming = xgb_prediction_df[xgb_prediction_df$prediction == 0, ]
dummy_predicted_not_gaming = dummy_prediction_df[dummy_prediction_df$prediction == 0, ]

rf_conditional_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=rf_predicted_gaming,
                            family=binomial)
summary(rf_conditional_prediction_true)

rf_conditional_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=rf_predicted_not_gaming,
                             family=binomial)
summary(rf_conditional_prediction_false)
# -------------------------------

dt_conditional_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=dt_predicted_gaming,
                            family=binomial)
summary(dt_conditional_prediction_true)

dt_conditional_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=dt_predicted_not_gaming,
                             family=binomial)
summary(dt_conditional_prediction_false)

# -------------------------------

nn_conditional_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=nn_predicted_gaming,
                            family=binomial)
summary(nn_conditional_prediction_true)

nn_conditional_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=nn_predicted_not_gaming,
                             family=binomial)
summary(nn_conditional_prediction_false)

# -------------------------------

# xgb_conditional_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=xgb_predicted_gaming,
#                              family=binomial)
# summary(xgb_conditional_prediction_true)

xgb_conditional_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=xgb_predicted_not_gaming,
                              family=binomial)
summary(xgb_conditional_prediction_false)
# -------------------------------

dummy_conditional_prediction_true <- glmer(correct ~ gender + (1 | StudentID), data=dummy_predicted_gaming,
                               family=binomial)
summary(dummy_conditional_prediction_true)

dummy_conditional_prediction_false <- glmer(correct ~ gender + (1 | StudentID), data=dummy_predicted_not_gaming,
                                family=binomial)
summary(dummy_conditional_prediction_false)

```

