{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fc1f98-abbd-4f07-8c5f-474875ec1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3f991e-fe01-494c-984b-5b04a5aeed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = pd.read_csv('datashop_data.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470a62a1-2a83-42c5-b2cf-29cdbae63b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a small sample of 10k actions\n",
    "action_df = action_df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0251439d-a2a7-432a-a1fb-d16a8bb3f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = action_df[['Anon Student Id', 'Time', 'Level (Workspace Id)', 'Problem Name', 'Step Name', \n",
    "                       'Outcome', 'Help Level', 'Attempt At Step', 'KC Model(MATHia)', 'CF (Skill New p-Known)',\n",
    "                       'CF (Semantic Event Id)']]\n",
    "action_df.columns = ['user_id', 'server_time', 'section_id', 'problem_id', 'goalnode_id', \n",
    "                     'tutor_outcome', 'help_level', 'attempt', 'skill', 'pknow', 'semantic_event_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99817656-6308-4a25-9166-8b9f23580579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pknown_direct(row):\n",
    "    if row[0]==1:\n",
    "        return row[1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def incorrect(x):\n",
    "    if x in ['OK', 'OK_AMBIGUOUS']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def problem_step_count_last5(window):\n",
    "    return (window == window.iloc[-1]).sum()\n",
    "def prob_step_first_att(row):\n",
    "    if (row[0], row[1]) in prob_step_set:\n",
    "        return 0\n",
    "    else:\n",
    "        prob_step_set.add((row[0], row[1]))\n",
    "        return 1\n",
    "\n",
    "def step_first_att(row):\n",
    "    if row in step_set:\n",
    "        return 0\n",
    "    else:\n",
    "        step_set.add(row)\n",
    "        return 1\n",
    "\n",
    "def getFeatures(df):\n",
    "    feature_df = df.copy()\n",
    "    if len(feature_df) - len(feature_df.dropna())>0:\n",
    "        raise ValueError('The input DataFrame contains NaNs')\n",
    "    feature_df['duration'] = feature_df.server_time.diff().to_numpy()/1000\n",
    "    feature_df.loc[feature_df[feature_df['user_id'].shift() != feature_df['user_id']].index, 'duration'] = np.nan\n",
    "    feature_df.drop(feature_df[feature_df.duration<feature_df.duration.quantile(0.025)].index, inplace=True)\n",
    "    feature_df.drop(feature_df[feature_df.duration>feature_df.duration.quantile(0.975)].index, inplace=True)\n",
    "    feature_df['assess_OK'] = feature_df.tutor_outcome.apply(lambda x: 1 if x=='OK' else 0)\n",
    "    feature_df['assess_BUG'] = feature_df.tutor_outcome.apply(lambda x: 1 if x=='JIT' else 0)\n",
    "    feature_df['assess_ERROR'] = feature_df.tutor_outcome.apply(lambda x: 1 if x=='ERROR' else 0)\n",
    "    feature_df['assess_INITIAL_HINT'] = feature_df.tutor_outcome.apply(lambda x: 1 if x=='INITIAL_HINT' else 0)\n",
    "    feature_df['duration_sd'] = feature_df[['duration']].apply(zscore, nan_policy='omit')\n",
    "    global prob_step_set, step_set\n",
    "    prob_step_set = set()\n",
    "    step_set = set()\n",
    "    feature_df['prob_first_att'] = feature_df[['problem_id', 'goalnode_id']].apply(prob_step_first_att, axis=1).values\n",
    "    feature_df['step_first_att'] = feature_df.goalnode_id.apply(step_first_att).values\n",
    "    correct_attempts = feature_df[['user_id', 'goalnode_id', 'assess_OK']].groupby(['user_id', 'goalnode_id']).sum()\n",
    "    count_attempts = feature_df[['user_id', 'goalnode_id', 'assess_OK']].groupby(['user_id', 'goalnode_id']).count()\n",
    "    wrong_attempts = count_attempts - correct_attempts\n",
    "    error_perc = wrong_attempts/count_attempts\n",
    "    feature_df['wrong_attempts'] = feature_df[['user_id', 'goalnode_id']].apply(lambda x: wrong_attempts.loc[(x[0], x[1]), 'assess_OK'], axis=1)\n",
    "    feature_df['error_perc'] = feature_df[['user_id', 'goalnode_id']].apply(lambda x: error_perc.loc[(x[0], x[1]), 'assess_OK'], axis=1)\n",
    "    max_attempts = feature_df[['user_id', 'problem_id', 'goalnode_id', 'attempt']].groupby(['user_id', 'problem_id', 'goalnode_id']).max()[['attempt']]\n",
    "    feature_df['numsteps'] = feature_df[['user_id', 'problem_id', 'goalnode_id']].apply(lambda x: max_attempts.loc[(x[0], x[1], x[2]), 'attempt'], axis=1)\n",
    "    feature_df['help_or_error'] = feature_df.tutor_outcome.apply(incorrect)\n",
    "    help_or_error = feature_df[['user_id', 'goalnode_id', 'help_or_error']].groupby(['user_id', 'goalnode_id']).sum()[['help_or_error']]\n",
    "    feature_df['help_and_errors_count'] = feature_df[['user_id', 'goalnode_id']].apply(lambda x: help_or_error.loc[(x[0], x[1]), 'help_or_error'], axis=1)\n",
    "    feature_df['error_count'] = feature_df['assess_BUG'] + feature_df['assess_ERROR']\n",
    "    feature_df['error_count_last_5'] = feature_df.error_count.rolling(5).sum()\n",
    "    feature_df['dur_sd_prev3'] = feature_df.duration_sd.rolling(3).sum()\n",
    "    feature_df['dur_sd_prev5'] = feature_df.duration_sd.rolling(5).sum()\n",
    "    feature_df['assess_HINT_LEVEL_CHANGE'] = feature_df.tutor_outcome.apply(lambda x: 1 if x=='HINT_LEVEL_CHANGE' else 0)\n",
    "    feature_df['help_attempts_last_8'] = feature_df.assess_HINT_LEVEL_CHANGE.rolling(8).sum()\n",
    "    le = LabelEncoder()\n",
    "    feature_df['goalnode_id'] = feature_df['problem_id']+feature_df['goalnode_id']\n",
    "    feature_df['encoded_goalnodes'] = le.fit_transform(feature_df.goalnode_id)\n",
    "    feature_df['prob_step_last_5'] = feature_df[['encoded_goalnodes']].rolling(5).apply(problem_step_count_last5)\n",
    "    return feature_df\n",
    "\n",
    "def getClipsIDs(feat_df):\n",
    "    feat = feat_df.copy()\n",
    "    refined_clips = {}\n",
    "    for size in [8,7,6,5,4,3,2,1]:\n",
    "        clips = feat.loc[feat.loc[~feat.index.duplicated(keep='first')].duration.rolling(size).sum()<=20].index\n",
    "        if len(clips)==0:\n",
    "            continue\n",
    "        refined_clips[size] = [clips[0]]\n",
    "        for i in clips:\n",
    "            if i-refined_clips[size][-1]>=size:\n",
    "                refined_clips[size].append(i)\n",
    "        dropIDs = []\n",
    "        uniqueIDs = feat.loc[~feat.index.duplicated(keep='first')].index.to_list()\n",
    "        for clip_id in refined_clips[size]:\n",
    "            pos = bisect(uniqueIDs, clip_id)\n",
    "            dropIDs.extend(uniqueIDs[pos-size:pos])\n",
    "        feat = feat.drop(index=dropIDs)\n",
    "    return refined_clips\n",
    "\n",
    "def getSimpleClipsIDs(feat_df):\n",
    "    feat = feat_df.copy()\n",
    "    refined_clips = {}\n",
    "    for size in [8,7,6,5,4,3,2]:\n",
    "        clips = feat.loc[feat.duration.rolling(size).sum()<=20].index.to_list()\n",
    "        if len(clips)==0:\n",
    "            continue\n",
    "        refined_clips[size] = [clips[0]]\n",
    "        for i in clips:\n",
    "            if i-refined_clips[size][-1]>=size:\n",
    "                refined_clips[size].append(i)\n",
    "        dropIDs = []\n",
    "        uniqueIDs = feat.index.to_list()\n",
    "        for clip_id in refined_clips[size]:\n",
    "            pos = bisect(uniqueIDs, clip_id)\n",
    "            dropIDs.extend(uniqueIDs[pos-size:pos])\n",
    "        feat = feat.drop(index=dropIDs)\n",
    "    for k, v in refined_clips.items():\n",
    "        refined_clips[k] = feat_df.loc[v]['semantic_event_id'].to_list()\n",
    "    return refined_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8c4d2b-c65f-4133-8d69-1bc925960a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_input = action_df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "features = getFeatures(df_to_input.sort_values(['user_id', 'server_time']))\n",
    "features['pknow_direct'] = features[['attempt', 'pknow']].apply(pknown_direct, axis=1)\n",
    "features['pknow'] = features.pknow.astype(float)\n",
    "features['pknow_direct'] = features.pknow_direct.astype(float)\n",
    "feats_per_user = {uid: features[features.user_id==uid] for uid in features.user_id.unique()}\n",
    "clipIDs = {user_id: getClipsIDs(feats_per_user[user_id]) for user_id in feats_per_user.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10819952-ee9a-4872-ada9-d0f9a02b6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processClips(feat_df, clipIDs):\n",
    "    feat = feat_df.copy()\n",
    "    clips = feat.head().describe().unstack().to_frame().T\n",
    "    funique = feat[~feat.index.duplicated()]\n",
    "    for size in range(2, 9):\n",
    "        if size in clipIDs.keys():\n",
    "            for ix in clipIDs[size]:\n",
    "                start = funique.loc[:ix].tail(size).index[0]\n",
    "                cur = feat.loc[start:ix].describe().unstack().to_frame().T\n",
    "                cur.index=[ix]\n",
    "                clips = pd.concat((clips, cur))\n",
    "    clips.columns = [f'{i[0]}_{i[1]}' for i in clips.columns]\n",
    "    for f in feat.columns:\n",
    "        clips[(f+'_sum')] = clips[(f+'_mean')] * clips[(f+'_count')]\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ae1bfc-7f3e-41b0-afed-5db3bfd95706",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = {sid:processClips(feats_per_user[sid].drop(\n",
    "    ['user_id', 'problem_id', 'tutor_outcome',\n",
    "    'goalnode_id', 'server_time', 'attempt', 'help_level',\n",
    "    'section_id', 'skill', 'help_or_error', 'semantic_event_id',\n",
    "    'encoded_goalnodes', 'error_count'], axis=1), clipIDs[sid]) for sid in feats_per_user.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35aed44-d780-487c-892a-bb9fbbf52bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order of features that the classifiers expect\n",
    "order = ['assess_BUG_25%', 'assess_BUG_50%', 'assess_BUG_75%',\n",
    "       'assess_BUG_count', 'assess_BUG_max', 'assess_BUG_mean',\n",
    "       'assess_BUG_min', 'assess_BUG_std', 'assess_BUG_sum',\n",
    "       'assess_OK_25%', 'assess_OK_50%', 'assess_OK_75%',\n",
    "       'assess_OK_count', 'assess_OK_max', 'assess_OK_mean',\n",
    "       'assess_OK_min', 'assess_OK_std', 'assess_OK_sum',\n",
    "       'assess_ERROR_25%', 'assess_ERROR_50%', 'assess_ERROR_75%',\n",
    "       'assess_ERROR_count', 'assess_ERROR_max', 'assess_ERROR_mean',\n",
    "       'assess_ERROR_min', 'assess_ERROR_std', 'assess_ERROR_sum',\n",
    "       'assess_INITIAL_HINT_25%', 'assess_INITIAL_HINT_50%',\n",
    "       'assess_INITIAL_HINT_75%', 'assess_INITIAL_HINT_count',\n",
    "       'assess_INITIAL_HINT_max', 'assess_INITIAL_HINT_mean',\n",
    "       'assess_INITIAL_HINT_min', 'assess_INITIAL_HINT_std',\n",
    "       'assess_INITIAL_HINT_sum', 'dur_sd_prev3_25%', 'dur_sd_prev3_50%',\n",
    "       'dur_sd_prev3_75%', 'dur_sd_prev3_count', 'dur_sd_prev3_max',\n",
    "       'dur_sd_prev3_mean', 'dur_sd_prev3_min', 'dur_sd_prev3_std',\n",
    "       'dur_sd_prev3_sum', 'dur_sd_prev5_25%', 'dur_sd_prev5_50%',\n",
    "       'dur_sd_prev5_75%', 'dur_sd_prev5_count', 'dur_sd_prev5_max',\n",
    "       'dur_sd_prev5_mean', 'dur_sd_prev5_min', 'dur_sd_prev5_std',\n",
    "       'dur_sd_prev5_sum', 'duration_sd_25%', 'duration_sd_50%',\n",
    "       'duration_sd_75%', 'duration_sd_count', 'duration_sd_max',\n",
    "       'duration_sd_mean', 'duration_sd_min', 'duration_sd_std',\n",
    "       'duration_sd_sum', 'error_count_last_5_25%',\n",
    "       'error_count_last_5_50%', 'error_count_last_5_75%',\n",
    "       'error_count_last_5_count', 'error_count_last_5_max',\n",
    "       'error_count_last_5_mean', 'error_count_last_5_min',\n",
    "       'error_count_last_5_std', 'error_count_last_5_sum',\n",
    "       'error_perc_25%', 'error_perc_50%', 'error_perc_75%',\n",
    "       'error_perc_count', 'error_perc_max', 'error_perc_mean',\n",
    "       'error_perc_min', 'error_perc_std', 'error_perc_sum',\n",
    "       'help_and_errors_count_25%', 'help_and_errors_count_50%',\n",
    "       'help_and_errors_count_75%', 'help_and_errors_count_count',\n",
    "       'help_and_errors_count_max', 'help_and_errors_count_mean',\n",
    "       'help_and_errors_count_min', 'help_and_errors_count_std',\n",
    "       'help_and_errors_count_sum', 'help_attempts_last_8_25%',\n",
    "       'help_attempts_last_8_50%', 'help_attempts_last_8_75%',\n",
    "       'help_attempts_last_8_count', 'help_attempts_last_8_max',\n",
    "       'help_attempts_last_8_mean', 'help_attempts_last_8_min',\n",
    "       'help_attempts_last_8_std', 'help_attempts_last_8_sum',\n",
    "       'numsteps_25%', 'numsteps_50%', 'numsteps_75%', 'numsteps_count',\n",
    "       'numsteps_max', 'numsteps_mean', 'numsteps_min', 'numsteps_std',\n",
    "       'numsteps_sum', 'pknow_25%', 'pknow_50%', 'pknow_75%',\n",
    "       'pknow_count', 'pknow_direct_25%', 'pknow_direct_50%',\n",
    "       'pknow_direct_75%', 'pknow_direct_count', 'pknow_direct_max',\n",
    "       'pknow_direct_mean', 'pknow_direct_min', 'pknow_direct_std',\n",
    "       'pknow_direct_sum', 'pknow_max', 'pknow_mean', 'pknow_min',\n",
    "       'pknow_std', 'pknow_sum', 'prob_first_att_25%',\n",
    "       'prob_first_att_50%', 'prob_first_att_75%', 'prob_first_att_count',\n",
    "       'prob_first_att_max', 'prob_first_att_mean', 'prob_first_att_min',\n",
    "       'prob_first_att_std', 'prob_first_att_sum', 'prob_step_last_5_25%',\n",
    "       'prob_step_last_5_50%', 'prob_step_last_5_75%',\n",
    "       'prob_step_last_5_count', 'prob_step_last_5_max',\n",
    "       'prob_step_last_5_mean', 'prob_step_last_5_min',\n",
    "       'prob_step_last_5_std', 'prob_step_last_5_sum',\n",
    "       'step_first_att_25%', 'step_first_att_50%', 'step_first_att_75%',\n",
    "       'step_first_att_count', 'step_first_att_max',\n",
    "       'step_first_att_mean', 'step_first_att_min', 'step_first_att_std',\n",
    "       'step_first_att_sum', 'wrong_attempts_25%', 'wrong_attempts_50%',\n",
    "       'wrong_attempts_75%', 'wrong_attempts_count', 'wrong_attempts_max',\n",
    "       'wrong_attempts_mean', 'wrong_attempts_min', 'wrong_attempts_std',\n",
    "       'wrong_attempts_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91879279-3465-4efb-82f2-e38c9f1c0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df83a5a4-8b9d-4768-8e72-4acbebdd6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers[-3].predict(processed['some_student_id'][order].dropna())[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
