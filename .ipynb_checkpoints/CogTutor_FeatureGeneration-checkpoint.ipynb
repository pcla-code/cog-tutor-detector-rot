{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da623dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data_Logs/2021_Mathia_Log.csv\") #New Data\n",
    "#df = pd.read_csv(\"Data_Logs/DataDetectorsTextReplays-NL.csv\") #Old Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode Outcome\n",
    "df =pd.concat([df,pd.get_dummies(df['Assess'], prefix='assess')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_without_outlier(x): # x: series\n",
    "    iqr = x.quantile(.9) - x.quantile(.1)\n",
    "    y = x[x.between(x.quantile(.1) - 1.5*iqr, x.quantile(.9) + 1.5*iqr)]\n",
    "    return [y.mean(), y.std()]\n",
    "\n",
    "def isNaN(num): \n",
    "    return num != num\n",
    "\n",
    "def process_clip(clip): #turn a clip into descriptive statistics for all feature columns\n",
    "    row_dict = {}\n",
    "    description_df = clip.describe()\n",
    "    sum_df = clip.sum()\n",
    "    for col in description_df.columns:\n",
    "        description = description_df[col]\n",
    "        for index,data in description.iteritems():\n",
    "            row_dict[col+\"_\"+index] = data\n",
    "        row_dict[col + \"_sum\"] = sum_df[col]\n",
    "    row_dict['StudentID'] = clip['Student'].iloc[0]\n",
    "    return row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate features\n",
    "\n",
    "stuID=\"\"\n",
    "prob_name=\"\"\n",
    "step = \"\"\n",
    "addition_list = []\n",
    "prob_list = []\n",
    "step_list = []\n",
    "error_count_last_5 = [0,0,0,0,0]\n",
    "help_attempts_last_8 = [0,0,0,0,0,0,0,0]\n",
    "prob_step_last_5 = [\"\",\"\",\"\",\"\",\"\"]\n",
    "row_count = 0\n",
    "\n",
    "for index,data in df.iterrows():\n",
    "    row_dict = {}\n",
    "    if (not stuID == data['Student']):\n",
    "        stuID = data['Student']\n",
    "        prob_list = []\n",
    "        step_list = []\n",
    "        error_count_last_5 = [0,0,0,0,0]\n",
    "        help_attempts_last_8 = [0,0,0,0,0,0,0,0]\n",
    "        prob_step_last_5 = [\"\",\"\",\"\",\"\",\"\"]\n",
    "        row_count = 0\n",
    "    \n",
    "    prob_name = data['Celltype']\n",
    "    step = data['Cell']\n",
    "    \n",
    "    #first time attempting this problem\n",
    "    if (not prob_name in prob_list):\n",
    "        row_dict['prob_first_att'] = 1\n",
    "        prob_list.append(prob_name)\n",
    "    else:\n",
    "        row_dict['prob_first_att'] = 0\n",
    "        \n",
    "    #first time this step\n",
    "    if (not step in step_list):\n",
    "        row_dict['step_first_att'] = 1\n",
    "        row_dict['pknow_direct'] = data['pknow']\n",
    "        step_list.append(prob_name)\n",
    "    else:\n",
    "        row_dict['step_first_att'] = 0\n",
    "        row_dict['pknow_direct'] = -1\n",
    "        \n",
    "    if (data['Assess'] == 'ERROR' or data['Assess'] == 'BUG'):\n",
    "        error_count_last_5[row_count % 5] = 1\n",
    "    else:\n",
    "        error_count_last_5[row_count % 5] = 0\n",
    "    \n",
    "    if (data['Assess'] == 'INITIAL_HINT' or data['Assess'] == 'HINT_LEVEL_CHANGE'):\n",
    "        help_attempts_last_8[row_count % 8] = 1\n",
    "    else:\n",
    "        help_attempts_last_8[row_count % 8] = 0\n",
    "        \n",
    "    prob_step_last_5[row_count % 5] = step\n",
    "        \n",
    "    row_dict['error_count_last_5'] = sum(error_count_last_5)\n",
    "    row_dict['help_attempts_last_8'] = sum(help_attempts_last_8)\n",
    "    row_dict['prob_step_last_5'] = prob_step_last_5.count(step)\n",
    "    \n",
    "    row_count += 1\n",
    "    addition_list.append(row_dict)\n",
    "\n",
    "new_df = pd.DataFrame(addition_list)\n",
    "    \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdbf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_df], axis=1) #add new features to old data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee56d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_p_step = df.groupby('Cell', sort=False)\n",
    "time_mean_series = grouped_p_step['time'].agg(mean_without_outlier) #find mean time for each problem step without outliers\n",
    "print(time_mean_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_list = []\n",
    "for row in df.itertuples():\n",
    "    row_dict = {}\n",
    "    if(not isNaN(row[3])): #row[3] - Cell aka problem step\n",
    "        #time_mean_series[row[3]][0] - mean\n",
    "        #time_mean_series[row[3]][1] - standard deviation\n",
    "        if (time_mean_series[row[3]][1] == 0): row_dict['duration_sd'] = 0 #if this cell had 0 standard deviation\n",
    "        else: row_dict['duration_sd'] = abs(row[8] - time_mean_series[row[3]][0])/(time_mean_series[row[3]][1])\n",
    "        addition_list.append(row_dict)\n",
    "    else: row_dict['duration_sd'] = 'nan'\n",
    "\n",
    "new_df = pd.DataFrame(addition_list)\n",
    "    \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267380b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_df], axis=1) #add new features to old data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caeaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate features\n",
    "#duration in standard deviation units\n",
    "\n",
    "addition_list = []\n",
    "dur_sd_prev3 =[0,0,0]\n",
    "dur_sd_prev5 =[0,0,0,0,0]\n",
    "stuID = \"\"\n",
    "for row in df.itertuples():\n",
    "    row_dict = {}\n",
    "    if (not stuID == row[1]):\n",
    "        dur_sd_prev3 =[0,0,0]\n",
    "        dur_sd_prev5 =[0,0,0,0,0]\n",
    "        stuID = row[1]\n",
    "    if(not isNaN(row[22])):\n",
    "        dur_sd_prev3[row[0]%3] = row[22]\n",
    "        dur_sd_prev5[row[0]%5] = row[22]\n",
    "    else:\n",
    "        dur_sd_prev3[row[0]%3] = 0\n",
    "        dur_sd_prev5[row[0]%5] = 0\n",
    "    row_dict['dur_sd_prev3'] = sum(dur_sd_prev3)\n",
    "    row_dict['dur_sd_prev5'] = sum(dur_sd_prev5)\n",
    "    addition_list.append(row_dict)\n",
    "\n",
    "new_df = pd.DataFrame(addition_list)\n",
    "                       \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate features\n",
    "#Counting Errors and OKs\n",
    "\n",
    "stuID = \"\"\n",
    "Cell = \"\"\n",
    "err_dict = {}\n",
    "help_err_dict = {}\n",
    "tot_dict = {}\n",
    "for row in df.itertuples():\n",
    "\n",
    "    if (not stuID == row[1]):\n",
    "        stuID = row[1]\n",
    "    Cell = row[3]\n",
    "    Assess = row[2]\n",
    "    key = (stuID,Cell)\n",
    "    if(key in tot_dict):\n",
    "        tot_dict[key] = tot_dict[key] + 1\n",
    "    else:\n",
    "        tot_dict[key] = 1\n",
    "    if(not key in err_dict):\n",
    "        err_dict[key] = 0\n",
    "    if(Assess == 'ERROR' or Assess == 'BUG'):\n",
    "        if(key in err_dict):\n",
    "            err_dict[key] = err_dict[key] + 1\n",
    "        else:\n",
    "            err_dict[key] = 1\n",
    "    if(not key in help_err_dict):\n",
    "        help_err_dict[key] = 0\n",
    "    if(Assess != 'OK'):\n",
    "        if(key in help_err_dict):\n",
    "            help_err_dict[key] = help_err_dict[key] + 1\n",
    "        else:\n",
    "            help_err_dict[key] = 1\n",
    "\n",
    "addition_list = []\n",
    "for row in df.itertuples():\n",
    "    row_dict = {}\n",
    "    stuID = row[1]\n",
    "    Cell = row[3]\n",
    "    key = (stuID,Cell)\n",
    "    row_dict['wrong_attempts'] = err_dict[key]\n",
    "    row_dict['error_perc'] = err_dict[key] / tot_dict[key]\n",
    "    row_dict['help_and_errors_count'] = help_err_dict[key]\n",
    "    addition_list.append(row_dict)\n",
    "\n",
    "new_df = pd.DataFrame(addition_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd391b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52789ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"Data_Logs/full_features.csv\", index=False) #save new features\n",
    "df.to_csv(\"Data_Logs/full_features_old_data.csv\", index=False) #save old features\n",
    "\n",
    "#stop here, go back and rerun for the old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep rows for the ready to code A 600\n",
    "#New Data Section\n",
    "df_ready_to_code = pd.read_csv(\"Data_Logs/ready_to_code_A_600.csv\")\n",
    "df_full_features = pd.read_csv(\"Data_Logs/full_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.merge(df_ready_to_code, df_full_features, on = ['Student','Assess','Cell','Celltype','answer','prod','pknow','numsteps','time'])\n",
    "df_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.to_csv(\"Data_Logs/selected_clips.csv\") #selected_clips for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded_clips = pd.read_csv(\"Data_Logs/ready_to_code_A_600_NN.csv\") #pull ending indexes\n",
    "starting_row = 0\n",
    "stats_list = []\n",
    "for row in df_coded_clips.itertuples():\n",
    "    df_clip = df_selected.iloc[starting_row:row[2]]\n",
    "    starting_row = row[2] # \n",
    "    stats_dict = process_clip(df_clip)\n",
    "    stats_dict['Target'] = row[4]\n",
    "    if(row[3] != \"?\" and stats_dict['time_mean']<10000 and stats_dict['duration_sd_mean']<10 and stats_dict['dur_sd_prev3_mean'] < 10 and stats_dict['dur_sd_prev5_mean'] < 10): stats_list.append(stats_dict)\n",
    "new_df = pd.DataFrame(stats_list)\n",
    "new_df.to_csv(\"training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0992c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep rows for the observationsALG-Adriana-combined\n",
    "#Old Data Section\n",
    "df_coded_clips = pd.read_csv(\"Data_Logs/observationsALG-Adriana-combined.csv\")\n",
    "df_full_features = pd.read_csv(\"Data_Logs/full_features_old_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be45cad-708b-400f-bb89-f4cb38ce3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_features = df_full_features[df_full_features['text-replay-label'] != '.']\n",
    "#df_full_features.drop(df_full_features.columns[0], axis=1, inplace=True)\n",
    "df_full_features.reset_index(inplace = True, drop=True)\n",
    "df_full_features.to_csv(\"Data_Logs/old_data_selected_clips.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca147e-1c63-424b-a990-2f0a3a5eeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=[]\n",
    "for row in df_coded_clips.itertuples():\n",
    "    index = df_full_features.index[df_full_features['num-for-obs'] == row[2]].values\n",
    "    if (index.size > 0): index_list.append(index[0])\n",
    "    else: index_list.append(-1)\n",
    "df_coded_clips[\"Clip_Start_Index\"] = index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57895415-7730-4619-9ab2-f3c20982e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded_clips = df_coded_clips[df_coded_clips['Clip_Start_Index'] != -1] #drop missing clips\n",
    "df_coded_clips.to_csv(\"Data_Logs/old_data_labels.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0d86d-4153-478d-a57d-da9fbf80a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coded_clips = pd.read_csv(\"Data_Logs/old_data_labels.csv\")\n",
    "df_selected = pd.read_csv(\"Data_Logs/old_data_selected_clips.csv\")\n",
    "starting_row = 0\n",
    "stats_list = []\n",
    "for row in df_coded_clips.itertuples():\n",
    "    df_clip = df_selected.iloc[starting_row:row[5]]\n",
    "    starting_row = row[5]\n",
    "    stats_dict = process_clip(df_clip)\n",
    "    stats_dict['Target'] = row[4]\n",
    "    \n",
    "    if(row[3] != \"?\" and stats_dict['time_mean']<10000 and stats_dict['duration_sd_mean']<10 and stats_dict['dur_sd_prev3_mean'] < 10 and stats_dict['dur_sd_prev5_mean'] < 10): stats_list.append(stats_dict)\n",
    "    \n",
    "new_df = pd.DataFrame(stats_list)\n",
    "new_df.to_csv(\"old_training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de46e12-9de6-4df3-a639-92e39ef50646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
